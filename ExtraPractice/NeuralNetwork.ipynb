{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question#2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fp8T3lv44vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing libraries for the Boston housing dataset\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import matplotlib.pyplot as plt #For plot generation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVC3q8bi5RfN",
        "colab_type": "code",
        "outputId": "b26a956a-0049-40ce-c356-d7bf5bc5f40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#Importing dataset from the keras.datasets and later on splitting the dataset into test and training set\n",
        "\n",
        "from keras.datasets import boston_housing\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 2us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLTrCZGz5bl8",
        "colab_type": "code",
        "outputId": "1052c4ec-24c1-4648-8a9e-5e29a7524cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Here we are trying to check the shape of the dataset and the sample values from training and test dataset\n",
        "print(f'Training data : {train_data.shape}')\n",
        "print(f'Test data : {test_data.shape}')\n",
        "print(f'Training sample : {train_data[0]}')\n",
        "print(f'Training target sample : {train_targets[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data : (404, 13)\n",
            "Test data : (102, 13)\n",
            "Training sample : [  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
            "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
            "Training target sample : 15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXeYvaDz5eRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Since the data may vary in scaling so we have performed normalization\n",
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "infp-Dbt5h8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "0642e5a0-379a-4979-c339-dd61a117a078"
      },
      "source": [
        "#importing libararies for building network\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "#building model and passed it on to single dense layer with activation function as RELU\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "#Using Mean square error loss\n",
        "    model.compile(optimizer='rmsprop',\n",
        "              loss='mse',\n",
        "              metrics=['mae'])\n",
        "    return model\n",
        "model=build_model()\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 64)                896       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g02b65GV6SnH",
        "colab_type": "code",
        "outputId": "746fe6b4-4805-425c-e5b5-6bbffa44701f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Performing cross validation on the dataset\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "\n",
        "for i in range(k):\n",
        "    print(f'Processing fold # {i}')\n",
        "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
        "    \n",
        "    partial_train_data = np.concatenate(\n",
        "                            [train_data[:i * num_val_samples],\n",
        "                            train_data[(i+1) * num_val_samples:]],\n",
        "                            axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "                            [train_targets[:i * num_val_samples],\n",
        "                            train_targets[(i+1)*num_val_samples:]],\n",
        "                            axis=0)\n",
        "    model = build_model()\n",
        "    model.fit(partial_train_data,\n",
        "              partial_train_targets,\n",
        "              epochs=num_epochs,\n",
        "              batch_size=1,\n",
        "              verbose=0)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing fold # 0\n",
            "Processing fold # 1\n",
            "Processing fold # 2\n",
            "Processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuGJTiTh6lsA",
        "colab_type": "code",
        "outputId": "c80cb723-5cd6-4a6f-af4c-9eceb8138def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Cross checking the mean scores \n",
        "print(f'all_scores : {all_scores}')\n",
        "print(f'mean all scores : {np.mean(all_scores)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all_scores : [1.9053592115345568, 2.4013640573709316, 2.5634595120307244, 2.5956920763053515]\n",
            "mean all scores : 2.366468714310391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wza1A-pR6no5",
        "colab_type": "code",
        "outputId": "1b953cc7-b1d0-4cfe-a9ac-cdc17db028ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Building the model and fit it with the training data\n",
        "model = build_model()\n",
        "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImKfPb2l6qxE",
        "colab_type": "code",
        "outputId": "5c750197-2df6-4419-af0e-0e5c2bdab771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Got the test score for the Boston housing dataset\n",
        "test_mae_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.523820764878217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}